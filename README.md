ğŸ“– Introduction

aibody is a future-oriented open-source AI body perception framework designed to deeply integrate computer vision with human body science. Whether you're building intelligent fitness apps, developing medical rehabilitation systems, or creating immersive VR experiences, aibody provides you with powerful body data perception capabilities.

We believe everyone's body deserves to be digitally understood. With aibody, you can easily build your own digital twin body.

âœ¨ Key Features

Module	Description	Status	
Pose Estimation Engine	2D/3D real-time keypoint detection with 95%+ accuracy	âœ… Available	
Action Recognition System	Custom action classification with anomaly alerts	âœ… Available	
Physiological Data Fusion	Integration with wearables (HR, SpO2, etc.)	ğŸš§ In Dev	
Digital Twin Generation	Building personalized virtual body models	ğŸš§ In Dev	
Cloud Sync Service	Real-time data cloud upload & multi-device sync	ğŸ“… Planned	

ğŸš€ Quick Start

Requirements
- Python 3.8+
- CUDA 11.0+ (recommended for GPU acceleration)
- Webcam or video file

Installation

```bash
# Clone repository
git clone https://github.com/erayorg/aibody.git
cd aibody

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Download pre-trained models
python scripts/download_models.py
```

Run Examples

```bash
# Start real-time pose detection
python examples/pose_estimation.py --source 0  # 0 for default webcam

# Run web interface
python -m aibody.web.app
# Visit http://localhost:8000
```

ğŸ“ Project Structure

```
aibody/
â”œâ”€â”€ aibody/                 # Core library
â”‚   â”œâ”€â”€ core/               # Pose estimation core
â”‚   â”œâ”€â”€ models/             # Pre-trained models
â”‚   â”œâ”€â”€ fusion/             # Multi-modal data fusion
â”‚   â””â”€â”€ digital_twin/       # Digital twin module
â”œâ”€â”€ examples/               # Example code
â”œâ”€â”€ web/                    # Web service & frontend
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ tests/                  # Test cases
â””â”€â”€ scripts/                # Utility scripts
```

ğŸ› ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Application Layer             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Fitness  â”‚ â”‚Medical â”‚ â”‚ VR     â”‚ â”‚
â”‚  â”‚   App   â”‚ â”‚ System  â”‚ â”‚ Game   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â”‚         API Layer (FastAPI)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Core Engine Layer            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Pose    â”‚ â”‚ Action   â”‚ â”‚ Data   â”‚ â”‚
â”‚  â”‚ Estimationâ”‚ â”‚Recognitionâ”‚ â”‚ Fusion â”‚ â”‚
â”‚  â”‚(MediaPipeâ”‚ â”‚  (LSTM)  â”‚ â”‚(Kalman)â”‚ â”‚
â”‚  â”‚ /YOLOv8) â”‚ â”‚          â”‚ â”‚ Filter)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Data Layer                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Video    â”‚ â”‚ Sensors  â”‚ â”‚ Cloud  â”‚ â”‚
â”‚  â”‚ Stream   â”‚ â”‚  (BLE)   â”‚ â”‚ (AWS)  â”‚ â”‚
â”‚  â”‚ (OpenCV) â”‚ â”‚          â”‚ â”‚        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ¤ Contributing

We welcome all forms of contributions!

Especially needed:
- ğŸ› Bug reports & fixes
- ğŸ“– Documentation translation & improvement
- ğŸ§  New model integration (pose estimation, action recognition)
- ğŸ¨ UI/UX design
- ğŸŒ Multi-language support

ğŸ“œ License

This project is open-sourced under the [MIT License](LICENSE).

ğŸ™ Acknowledgments

- [MediaPipe](https://mediapipe.dev) for powerful pose estimation foundation
- [PyTorch](https://pytorch.org) deep learning framework
- All contributors and community supporters
